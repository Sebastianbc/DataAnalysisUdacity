{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership = np.array([\n",
    "    [   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In a two dimensional numpy array the way to index data is first by row and then by column.\n",
    "There is no column names or label indexes in 2D numpy arrays as there is in pandas Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2328\n",
      "[[2328 2539]\n",
      " [6461 2691]]\n",
      "[1478 3877 3674 2328 2539]\n"
     ]
    }
   ],
   "source": [
    "# Accessing elements\n",
    "print(ridership[1, 3])\n",
    "print(ridership[1:3, 3:5])\n",
    "print(ridership[1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectorized operations must be made either by equal length rows or equal length columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1478 3877 3676 2333 2539]\n",
      "[   0 5355 5701 4952 6410 5509  324    2 5223 5385]\n"
     ]
    }
   ],
   "source": [
    "# Vectorized operations on rows or columns\n",
    "print(ridership[0, :] + ridership[1, :])\n",
    "print(ridership[:, 0] + ridership[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  3  4]\n",
      " [ 6  7  8]\n",
      " [10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "# Vectorized operations on entire arrays\n",
    "a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "b = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(ridership[0]) # Get the index of the maximum value in the spcified array's row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2342.6, 3239.9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "    \n",
    "    Hint: NumPy's argmax() function might be useful:\n",
    "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html\n",
    "    '''\n",
    "    overall_mean = ridership.mean()\n",
    "    mean_for_max = ridership[:, np.argmax(ridership[0])].mean()\n",
    "    \n",
    "    return (overall_mean, mean_for_max)\n",
    "\n",
    "mean_riders_for_max_station(ridership)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy axis argument\n",
    "a = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Axis 0 is vertically and axis 1 is horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "[12 15 18]\n",
      "[ 6 15 24]\n"
     ]
    }
   ],
   "source": [
    "print(a.sum())\n",
    "print(a.sum(axis=0)) # Sum is made on the columns\n",
    "print(a.sum(axis=1)) # Sum is made on the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3239.9, 1071.2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import my_decorators as mydec\n",
    "\n",
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership = np.array([\n",
    "    [   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])\n",
    "\n",
    "@mydec.timer\n",
    "def min_and_max_riders_per_day(ridership):\n",
    "    '''\n",
    "    Fill in this function. First, for each subway station, calculate the\n",
    "    mean ridership per day. Then, out of all the subway stations, return the\n",
    "    maximum and minimum of these values. That is, find the maximum\n",
    "    mean-ridership-per-day and the minimum mean-ridership-per-day for any\n",
    "    subway station.\n",
    "    '''\n",
    "    station = 0\n",
    "    means = list()\n",
    "    while station < len(ridership[0]):\n",
    "        means.append(ridership[:, station].mean())\n",
    "        station += 1\n",
    "\n",
    "    max_daily_ridership = max(means)\n",
    "    min_daily_ridership = min(means)\n",
    "    \n",
    "    return (max_daily_ridership, min_daily_ridership)\n",
    "\n",
    "min_and_max_riders_per_day(np.array(ridership))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3239.9, 1071.2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@mydec.timer\n",
    "def min_and_max_riders_per_day(ridership):\n",
    "    '''\n",
    "    Fill in this function. First, for each subway station, calculate the\n",
    "    mean ridership per day. Then, out of all the subway stations, return the\n",
    "    maximum and minimum of these values. That is, find the maximum\n",
    "    mean-ridership-per-day and the minimum mean-ridership-per-day for any\n",
    "    subway station.\n",
    "    '''\n",
    "    means = ridership.mean(axis=0)\n",
    "    max_daily_ridership = max(means)\n",
    "    min_daily_ridership = min(means)\n",
    "    \n",
    "    return (max_daily_ridership, min_daily_ridership)\n",
    "\n",
    "min_and_max_riders_per_day(ridership)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accessing elements of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership_df = pd.DataFrame(\n",
    "    data=[[   0,    0,    2,    5,    0],\n",
    "          [1478, 3877, 3674, 2328, 2539],\n",
    "          [1613, 4088, 3991, 6461, 2691],\n",
    "          [1560, 3392, 3826, 4787, 2613],\n",
    "          [1608, 4802, 3932, 4477, 2705],\n",
    "          [1576, 3933, 3909, 4979, 2685],\n",
    "          [  95,  229,  255,  496,  201],\n",
    "          [   2,    0,    1,   27,    0],\n",
    "          [1438, 3785, 3589, 4174, 2215],\n",
    "          [1342, 4043, 4009, 4665, 3033]],\n",
    "    index=['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "           '05-06-11', '05-07-11', '05-08-11', '05-09-11', '05-10-11'],\n",
    "    columns=['R003', 'R004', 'R005', 'R006', 'R007']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  0  3\n",
      "1  1  4\n",
      "2  2  5\n",
      "   A  B  C\n",
      "0  0  1  2\n",
      "1  3  4  5\n"
     ]
    }
   ],
   "source": [
    "# You can create a DataFrame out of a dictionary mapping column names to values\n",
    "df_1 = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "print(df_1)\n",
    "\n",
    "# You can also use a list of lists or a 2D NumPy array\n",
    "df_2 = pd.DataFrame([[0, 1, 2], [3, 4, 5]], columns=['A', 'B', 'C'])\n",
    "print(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R003    0\n",
      "R004    0\n",
      "R005    2\n",
      "R006    5\n",
      "R007    0\n",
      "Name: 05-01-11, dtype: int64\n",
      "R003    1608\n",
      "R004    4802\n",
      "R005    3932\n",
      "R006    4477\n",
      "R007    2705\n",
      "Name: 05-05-11, dtype: int64\n",
      "05-01-11       0\n",
      "05-02-11    1478\n",
      "05-03-11    1613\n",
      "05-04-11    1560\n",
      "05-05-11    1608\n",
      "05-06-11    1576\n",
      "05-07-11      95\n",
      "05-08-11       2\n",
      "05-09-11    1438\n",
      "05-10-11    1342\n",
      "Name: R003, dtype: int64\n",
      "2328\n"
     ]
    }
   ],
   "source": [
    "# Accessing elements\n",
    "print(ridership_df.iloc[0]) # Access row by index\n",
    "print(ridership_df.loc['05-05-11']) # Access row by index label\n",
    "print(ridership_df['R003']) # Access column\n",
    "print(ridership_df.iloc[1, 3]) # Access first row then column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          R003  R004  R005  R006  R007\n",
      "05-02-11  1478  3877  3674  2328  2539\n",
      "05-03-11  1613  4088  3991  6461  2691\n",
      "05-04-11  1560  3392  3826  4787  2613\n"
     ]
    }
   ],
   "source": [
    "print(ridership_df.iloc[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          R003  R005\n",
      "05-01-11     0     2\n",
      "05-02-11  1478  3674\n",
      "05-03-11  1613  3991\n",
      "05-04-11  1560  3826\n",
      "05-05-11  1608  3932\n",
      "05-06-11  1576  3909\n",
      "05-07-11    95   255\n",
      "05-08-11     2     1\n",
      "05-09-11  1438  3589\n",
      "05-10-11  1342  4009\n"
     ]
    }
   ],
   "source": [
    "print(ridership_df[['R003', 'R005']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A     3\n",
      "B    12\n",
      "dtype: int64\n",
      "0    3\n",
      "1    5\n",
      "2    7\n",
      "dtype: int64\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "print(df.sum())\n",
    "print(df.sum(axis=1))\n",
    "print(df.values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R006'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridership_df.iloc[0].idxmax() # Get the column name with the max element in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2342.6, 3239.9)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "    \n",
    "    This is the same as a previous exercise, but this time the\n",
    "    input is a Pandas DataFrame rather than a 2D NumPy array.\n",
    "    '''\n",
    "    # Get the station \"column\" with the maximum riders on the first day\n",
    "    max_rid_first_day = ridership.iloc[0].idxmax()\n",
    "    # Get the mean across both axes\n",
    "    overall_mean = ridership.mean(axis=None)\n",
    "    # Get the mean of that station with max riders on 1st day\n",
    "    mean_for_max = ridership[max_rid_first_day].mean()\n",
    "    \n",
    "    return (overall_mean, mean_for_max)\n",
    "\n",
    "mean_riders_for_max_station(ridership_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading data into a DataFrame\n",
    "Calculating correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.Series([1, 2, 3, 4])\n",
    "y = pd.Series([10, 11, 12, 13])\n",
    "\n",
    "mean_x = x.mean()\n",
    "mean_y = y.mean()\n",
    "\n",
    "diff_x = x - mean_x\n",
    "diff_y = y - mean_y\n",
    "\n",
    "sum_product = (diff_x * diff_y).sum()\n",
    "\n",
    "sum_sq_x = (diff_x ** 2).sum()\n",
    "sum_sq_y = (diff_y ** 2).sum()\n",
    "\n",
    "correlation = sum_product / (sum_sq_x * sum_sq_y)**0.5\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame vectorized operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c\n",
      "0  11  44  77\n",
      "1  22  55  88\n",
      "2  33  66  99\n"
     ]
    }
   ],
   "source": [
    "# Examples of vectorized operations on DataFrames:\n",
    "\n",
    "# Adding DataFrames with the column names\n",
    "df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]})\n",
    "print(df1 + df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   d\n",
      "0 NaN  74  47 NaN\n",
      "1 NaN  85  58 NaN\n",
      "2 NaN  96  69 NaN\n"
     ]
    }
   ],
   "source": [
    "# Adding DataFrames with overlapping column names \n",
    "df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "df2 = pd.DataFrame({'d': [10, 20, 30], 'c': [40, 50, 60], 'b': [70, 80, 90]})\n",
    "print(df1 + df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         a     b     c\n",
      "row1   NaN   NaN   NaN\n",
      "row2  32.0  65.0  98.0\n",
      "row3  23.0  56.0  89.0\n",
      "row4   NaN   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "# Adding DataFrames with overlapping row indexes\n",
    "df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]},\n",
    "                   index=['row1', 'row2', 'row3'])\n",
    "df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]},\n",
    "                   index=['row4', 'row3', 'row2'])\n",
    "print(df1 + df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ENTRIESn  EXITSn\n",
      "0       NaN     NaN\n",
      "1      23.0     8.0\n",
      "2      18.0    18.0\n",
      "3      71.0    54.0\n",
      "4     170.0    44.0\n",
      "5     214.0    42.0\n",
      "6      87.0    11.0\n",
      "7      10.0     3.0\n",
      "8      36.0    89.0\n",
      "9     153.0   333.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    2056161\n",
       "1    2056176\n",
       "2    2056176\n",
       "3    2056193\n",
       "4    2056319\n",
       "5    2056491\n",
       "6    2056567\n",
       "7    2056574\n",
       "8    2056521\n",
       "9    2056341\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cumulative entries and exits for one station for a few hours.\n",
    "entries_and_exits = pd.DataFrame({\n",
    "    'ENTRIESn': [3144312, 3144335, 3144353, 3144424, 3144594,\n",
    "                 3144808, 3144895, 3144905, 3144941, 3145094],\n",
    "    'EXITSn': [1088151, 1088159, 1088177, 1088231, 1088275,\n",
    "               1088317, 1088328, 1088331, 1088420, 1088753]\n",
    "})\n",
    "\n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits (entries in the first column, exits in the second) and\n",
    "    return a DataFrame with hourly entries and exits (entries in the\n",
    "    first column, exits in the second).\n",
    "    '''\n",
    "    print(entries_and_exits.diff())\n",
    "    return entries_and_exits['ENTRIESn'] - entries_and_exits['EXITSn']\n",
    "    \n",
    "get_hourly_entries_and_exits(entries_and_exits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame map()\n",
    "Runs a function that accepts and return a scalar value. Therefore when the map method is called from a pandas dataframe it behaves on every element in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a   b   c\n",
      "0  2  11   6\n",
      "1  3  21  11\n",
      "2  4  31  16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# DataFrame map()\n",
    "df = pd.DataFrame({\n",
    "    'a': [1, 2, 3],\n",
    "    'b': [10, 20, 30],\n",
    "    'c': [5, 10, 15]\n",
    "})\n",
    "    \n",
    "def add_one(x):\n",
    "    return x + 1\n",
    "    \n",
    "print(df.map(add_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Andre</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barry</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris</th>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dan</th>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emilio</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fred</th>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greta</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humbert</th>\n",
       "      <td>D</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivan</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        exam1 exam2\n",
       "Andre       F     F\n",
       "Barry       B     D\n",
       "Chris       C     F\n",
       "Dan         C     F\n",
       "Emilio      B     D\n",
       "Fred        C     F\n",
       "Greta       A     C\n",
       "Humbert     D     F\n",
       "Ivan        A     C\n",
       "James       B     D"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "letters = 'A', 'B', 'C', 'D', 'F'\n",
    "ranges = ((90, 100), (80, 89), (70, 79), (60, 69), (0, 59))\n",
    "    \n",
    "def convert_grades(grades):\n",
    "    '''\n",
    "    Fill in this function to convert the given DataFrame of numerical\n",
    "    grades to letter grades. Return a new DataFrame with the converted\n",
    "    grade.\n",
    "    \n",
    "    The conversion rule is:\n",
    "        90-100 -> A\n",
    "        80-89  -> B\n",
    "        70-79  -> C\n",
    "        60-69  -> D\n",
    "        0-59   -> F\n",
    "    '''\n",
    "    # As pd.map() method works with each DataFrame item at a time, we defined a helper function \n",
    "    # that receives one scalar value and returns it's category based on that value.\n",
    "    return grades.map(evaluate_grade)\n",
    "\n",
    "# Helper function\n",
    "def evaluate_grade(grade: int) -> str:\n",
    "    '''Evaluates whether a value is within a range and return it's category.'''\n",
    "    if grade >= 90: return 'A'\n",
    "    elif grade >= 80: return 'B'\n",
    "    elif grade >= 70: return 'C'\n",
    "    elif grade >= 60: return 'D'\n",
    "    elif grade >= 0: return 'F'\n",
    "\n",
    "convert_grades(grades_df)\n",
    "\n",
    "#grades_df.map(convert_grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a     3.0\n",
      "b    30.0\n",
      "c    15.0\n",
      "dtype: float64\n",
      "a     5\n",
      "b    50\n",
      "c    25\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': [4, 5, 3, 1, 2],\n",
    "    'b': [20, 10, 40, 50, 30],\n",
    "    'c': [25, 20, 5, 15, 10]\n",
    "})\n",
    "\n",
    "# DataFrame apply() - use case 2\n",
    "print(df.apply(np.mean))\n",
    "print(df.apply(np.max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     4.0\n",
       "b    40.0\n",
       "c    20.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def second_largest(df: pd.DataFrame) -> int:\n",
    "    '''\n",
    "    Return the second-largest value of  \n",
    "    the DataFrame's column.\n",
    "    '''\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].drop(df[col].argmax())\n",
    "    return df.apply(np.max)\n",
    "\n",
    "# Apply works on each column of the dataframe. It means the function passed into the \n",
    "# apply function must work with one dimensional arrays (numpy arrays, lists, pandas series)\n",
    "second_largest(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Adding a Series to a square DataFrame\n",
    "# The series index is mapped with the column names.\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print(df)\n",
    "    print('') # Create a blank line between outputs\n",
    "    print(df + s)\n",
    "    \n",
    "# Adding a Series to a one-row DataFrame \n",
    "# The series index is mapped with the column names.\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10], 1: [20], 2: [30], 3: [40]})\n",
    "    \n",
    "    print(df)\n",
    "    print('') # Create a blank line between outputs\n",
    "    print(df + s)\n",
    "\n",
    "# Adding a Series to a one-column DataFrame\n",
    "# As the index series is mapped to a dataframe with it's columns, just column '0' in dataframe gets added.All\n",
    "# the other columns get NaN values.\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10, 20, 30, 40]})\n",
    "    \n",
    "    print(df)\n",
    "    print('') # Create a blank line between outputs\n",
    "    print(df + s)\n",
    "    \n",
    "\n",
    "    \n",
    "# Adding when DataFrame column names match Series index\n",
    "# The series is added at the index level. Axis 1\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print(df)\n",
    "    print('') # Create a blank line between outputs\n",
    "    print(df + s)\n",
    "    \n",
    "# Adding when DataFrame column names don't match Series index\n",
    "# No value is operated an all elements get NaN\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print(df)\n",
    "    print('') # Create a blank line between outputs\n",
    "    print(df + s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pandas groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   value   even  above_three\n",
      "a      1  False        False\n",
      "b      3  False        False\n",
      "c      2   True        False\n",
      "d      4   True         True\n",
      "e      1  False        False\n",
      "f      6   True         True\n",
      "g      4   True         True\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Examine DataFrame\n",
    "print(example_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000017A8491AF50>\n",
      "<pandas.core.groupby.generic.SeriesGroupBy object at 0x0000017A83BD8850>\n"
     ]
    }
   ],
   "source": [
    "print(example_df.groupby('even'))\n",
    "print(example_df.groupby('even')['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{False: ['a', 'b', 'e'], True: ['c', 'd', 'f', 'g']}\n"
     ]
    }
   ],
   "source": [
    "# Examine groups\n",
    "grouped_data = example_df.groupby('even')\n",
    "# The groups attribute is a dictionary mapping keys to lists of row indexes\n",
    "print(grouped_data.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(False, False): ['a', 'b', 'e'], (True, False): ['c'], (True, True): ['d', 'f', 'g']}\n"
     ]
    }
   ],
   "source": [
    "# Group by multiple columns\n",
    "grouped_data = example_df.groupby(['even', 'above_three'])\n",
    "print(grouped_data.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       value  above_three\n",
      "even                     \n",
      "False      5            0\n",
      "True      16            3\n"
     ]
    }
   ],
   "source": [
    "# Get sum of each group\n",
    "grouped_data = example_df.groupby('even')\n",
    "print(grouped_data.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "even\n",
      "False     5\n",
      "True     16\n",
      "Name: value, dtype: int32\n",
      "\n",
      "\n",
      "even\n",
      "False     5\n",
      "True     16\n",
      "Name: value, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "grouped_data = example_df.groupby('even')\n",
    "\n",
    "# You can take one or more columns from the result DataFrame\n",
    "print(grouped_data.sum()['value'])\n",
    "\n",
    "print('\\n') # Blank line to separate results\n",
    "\n",
    "# You can also take a subset of columns from the grouped data before \n",
    "# collapsing to a DataFrame. In this case, the result is the same.\n",
    "print(grouped_data['value'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isPaid\n",
       "False    284821\n",
       "True     778327\n",
       "Name: numSubscribers, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grph_dsgn = pd.read_csv('./Datasets/GraphicDesign.csv')\n",
    "\n",
    "grph_dsgn.head()\n",
    "grph_dsgn.groupby('isPaid')['numSubscribers'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Standardize each group\n",
    "def standardize(xs):\n",
    "    return (xs - xs.mean()) / xs.std()\n",
    "grouped_data = example_df.groupby('even')\n",
    "print(grouped_data['value'].apply(standardize))\n",
    "    \n",
    "# Find second largest value in each group\n",
    "def second_largest(xs):\n",
    "    sorted_xs = xs.sort(inplace=False, ascending=False)\n",
    "    return sorted_xs.iloc[1]\n",
    "grouped_data = example_df.groupby('even')\n",
    "print(grouped_data['value'].apply(second_largest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame with cumulative entries and exits for multiple stations\n",
    "ridership_df = pd.DataFrame({\n",
    "    'UNIT': ['R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051'],\n",
    "    'TIMEn': ['00:00:00', '02:00:00', '04:00:00', '06:00:00', '08:00:00', '10:00:00', '12:00:00', '14:00:00', '16:00:00'],\n",
    "    'ENTRIESn': [3144312, 8936644, 3144335, 8936658, 3144353, 8936687, 3144424, 8936819, 3144594],\n",
    "    'EXITSn': [1088151, 13755385,  1088159, 13755393,  1088177, 13755598, 1088231, 13756191,  1088275]\n",
    "})\n",
    "\n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits and return a DataFrame with hourly entries and exits.\n",
    "    The hourly entries and exits should be calculated separately for\n",
    "    each station (the 'UNIT' column).\n",
    "    \n",
    "    Hint: Take a look at the `get_hourly_entries_and_exits()` function\n",
    "    you wrote in a previous quiz, DataFrame Vectorized Operations. If\n",
    "    you copy it here and rename it, you can use it and the `.apply()`\n",
    "    function to help solve this problem.\n",
    "    '''\n",
    "    group = entries_and_exits.groupby('UNIT')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATEn</th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>fog</th>\n",
       "      <th>hour</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>pressurei</th>\n",
       "      <th>rain</th>\n",
       "      <th>tempi</th>\n",
       "      <th>wspdi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05-01-11</td>\n",
       "      <td>4388333.0</td>\n",
       "      <td>2911002.0</td>\n",
       "      <td>R003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-02-11</td>\n",
       "      <td>4388348.0</td>\n",
       "      <td>2911036.0</td>\n",
       "      <td>R003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05-03-11</td>\n",
       "      <td>4389885.0</td>\n",
       "      <td>2912127.0</td>\n",
       "      <td>R003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05-04-11</td>\n",
       "      <td>4391507.0</td>\n",
       "      <td>2913223.0</td>\n",
       "      <td>R003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-05-11</td>\n",
       "      <td>4393043.0</td>\n",
       "      <td>2914284.0</td>\n",
       "      <td>R003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>05-01-11</td>\n",
       "      <td>14656120.0</td>\n",
       "      <td>14451774.0</td>\n",
       "      <td>R004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>05-02-11</td>\n",
       "      <td>14656174.0</td>\n",
       "      <td>14451851.0</td>\n",
       "      <td>R004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>05-03-11</td>\n",
       "      <td>14660126.0</td>\n",
       "      <td>14454734.0</td>\n",
       "      <td>R004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>05-04-11</td>\n",
       "      <td>14664247.0</td>\n",
       "      <td>14457780.0</td>\n",
       "      <td>R004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>05-05-11</td>\n",
       "      <td>14668301.0</td>\n",
       "      <td>14460818.0</td>\n",
       "      <td>R004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DATEn    ENTRIESn      EXITSn  UNIT  fog  hour   latitude  longitude  \\\n",
       "0  05-01-11   4388333.0   2911002.0  R003  NaN     0  40.689945 -73.872564   \n",
       "1  05-02-11   4388348.0   2911036.0  R003  NaN     0  40.689945 -73.872564   \n",
       "2  05-03-11   4389885.0   2912127.0  R003  NaN     0  40.689945 -73.872564   \n",
       "3  05-04-11   4391507.0   2913223.0  R003  NaN     0  40.689945 -73.872564   \n",
       "4  05-05-11   4393043.0   2914284.0  R003  NaN     0  40.689945 -73.872564   \n",
       "5  05-01-11  14656120.0  14451774.0  R004  NaN     0  40.691320 -73.867135   \n",
       "6  05-02-11  14656174.0  14451851.0  R004  NaN     0  40.691320 -73.867135   \n",
       "7  05-03-11  14660126.0  14454734.0  R004  NaN     0  40.691320 -73.867135   \n",
       "8  05-04-11  14664247.0  14457780.0  R004  NaN     0  40.691320 -73.867135   \n",
       "9  05-05-11  14668301.0  14460818.0  R004  NaN     0  40.691320 -73.867135   \n",
       "\n",
       "   pressurei  rain  tempi  wspdi  \n",
       "0        NaN   NaN    NaN    NaN  \n",
       "1        NaN   NaN    NaN    NaN  \n",
       "2        NaN   NaN    NaN    NaN  \n",
       "3        NaN   NaN    NaN    NaN  \n",
       "4        NaN   NaN    NaN    NaN  \n",
       "5        NaN   NaN    NaN    NaN  \n",
       "6        NaN   NaN    NaN    NaN  \n",
       "7        NaN   NaN    NaN    NaN  \n",
       "8        NaN   NaN    NaN    NaN  \n",
       "9        NaN   NaN    NaN    NaN  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subway_df = pd.DataFrame({\n",
    "    'UNIT': ['R003', 'R003', 'R003', 'R003', 'R003', 'R004', 'R004', 'R004',\n",
    "             'R004', 'R004'],\n",
    "    'DATEn': ['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "              '05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'ENTRIESn': [ 4388333,  4388348,  4389885,  4391507,  4393043, 14656120,\n",
    "                 14656174, 14660126, 14664247, 14668301],\n",
    "    'EXITSn': [ 2911002,  2911036,  2912127,  2913223,  2914284, 14451774,\n",
    "               14451851, 14454734, 14457780, 14460818],\n",
    "    'latitude': [ 40.689945,  40.689945,  40.689945,  40.689945,  40.689945,\n",
    "                  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.872564, -73.872564, -73.872564, -73.872564,\n",
    "                  -73.867135, -73.867135, -73.867135, -73.867135, -73.867135]\n",
    "})\n",
    "\n",
    "weather_df = pd.DataFrame({\n",
    "    'DATEn': ['05-01-11', '05-01-11', '05-02-11', '05-02-11', '05-03-11',\n",
    "              '05-03-11', '05-04-11', '05-04-11', '05-05-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'latitude': [ 40.689945,  40.69132 ,  40.689945,  40.69132 ,  40.689945,\n",
    "                  40.69132 ,  40.689945,  40.69132 ,  40.689945,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.867135, -73.872564, -73.867135, -73.872564,\n",
    "                  -73.867135, -73.872564, -73.867135, -73.872564, -73.867135],\n",
    "    'pressurei': [ 30.24,  30.24,  30.32,  30.32,  30.14,  30.14,  29.98,  29.98,\n",
    "                   30.01,  30.01],\n",
    "    'fog': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'rain': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'tempi': [ 52. ,  52. ,  48.9,  48.9,  54. ,  54. ,  57.2,  57.2,  48.9,  48.9],\n",
    "    'wspdi': [  8.1,   8.1,   6.9,   6.9,   3.5,   3.5,  15. ,  15. ,  15. ,  15. ]\n",
    "})\n",
    "\n",
    "subway_df.combine(weather_df, lambda s1, s2: s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function combine in module pandas.core.frame:\n",
      "\n",
      "combine(self, other: 'DataFrame', func: 'Callable[[Series, Series], Series | Hashable]', fill_value=None, overwrite: 'bool' = True) -> 'DataFrame'\n",
      "    Perform column-wise combine with another DataFrame.\n",
      "    \n",
      "    Combines a DataFrame with `other` DataFrame using `func`\n",
      "    to element-wise combine columns. The row and column indexes of the\n",
      "    resulting DataFrame will be the union of the two.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    other : DataFrame\n",
      "        The DataFrame to merge column-wise.\n",
      "    func : function\n",
      "        Function that takes two series as inputs and return a Series or a\n",
      "        scalar. Used to merge the two dataframes column by columns.\n",
      "    fill_value : scalar value, default None\n",
      "        The value to fill NaNs with prior to passing any column to the\n",
      "        merge func.\n",
      "    overwrite : bool, default True\n",
      "        If True, columns in `self` that do not exist in `other` will be\n",
      "        overwritten with NaNs.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        Combination of the provided DataFrames.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.combine_first : Combine two DataFrame objects and default to\n",
      "        non-null values in frame calling the method.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Combine using a simple function that chooses the smaller column.\n",
      "    \n",
      "    >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      "    >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      "    >>> take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2\n",
      "    >>> df1.combine(df2, take_smaller)\n",
      "       A  B\n",
      "    0  0  3\n",
      "    1  0  3\n",
      "    \n",
      "    Example using a true element-wise combine function.\n",
      "    \n",
      "    >>> df1 = pd.DataFrame({'A': [5, 0], 'B': [2, 4]})\n",
      "    >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      "    >>> df1.combine(df2, np.minimum)\n",
      "       A  B\n",
      "    0  1  2\n",
      "    1  0  3\n",
      "    \n",
      "    Using `fill_value` fills Nones prior to passing the column to the\n",
      "    merge function.\n",
      "    \n",
      "    >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n",
      "    >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      "    >>> df1.combine(df2, take_smaller, fill_value=-5)\n",
      "       A    B\n",
      "    0  0 -5.0\n",
      "    1  0  4.0\n",
      "    \n",
      "    However, if the same element in both dataframes is None, that None\n",
      "    is preserved\n",
      "    \n",
      "    >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n",
      "    >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [None, 3]})\n",
      "    >>> df1.combine(df2, take_smaller, fill_value=-5)\n",
      "        A    B\n",
      "    0  0 -5.0\n",
      "    1  0  3.0\n",
      "    \n",
      "    Example that demonstrates the use of `overwrite` and behavior when\n",
      "    the axis differ between the dataframes.\n",
      "    \n",
      "    >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      "    >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [-10, 1], }, index=[1, 2])\n",
      "    >>> df1.combine(df2, take_smaller)\n",
      "         A    B     C\n",
      "    0  NaN  NaN   NaN\n",
      "    1  NaN  3.0 -10.0\n",
      "    2  NaN  3.0   1.0\n",
      "    \n",
      "    >>> df1.combine(df2, take_smaller, overwrite=False)\n",
      "         A    B     C\n",
      "    0  0.0  NaN   NaN\n",
      "    1  0.0  3.0 -10.0\n",
      "    2  NaN  3.0   1.0\n",
      "    \n",
      "    Demonstrating the preference of the passed in dataframe.\n",
      "    \n",
      "    >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1], }, index=[1, 2])\n",
      "    >>> df2.combine(df1, take_smaller)\n",
      "       A    B   C\n",
      "    0  0.0  NaN NaN\n",
      "    1  0.0  3.0 NaN\n",
      "    2  NaN  3.0 NaN\n",
      "    \n",
      "    >>> df2.combine(df1, take_smaller, overwrite=False)\n",
      "         A    B   C\n",
      "    0  0.0  NaN NaN\n",
      "    1  0.0  3.0 1.0\n",
      "    2  NaN  3.0 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame.combine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
